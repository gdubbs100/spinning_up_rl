{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8806b7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.distributions as dist\n",
    "\n",
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcddfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = {\n",
    "    \"continuous\":False,\n",
    "    \"gravity\":-10.0,\n",
    "    \"enable_wind\": False,\n",
    "    \"wind_power\":15.0,\n",
    "    \"turbulence_power\":1.5\n",
    "}\n",
    "\n",
    "## create lunar lander\n",
    "env = gym.make_vec(\"LunarLander-v3\", num_envs= 3, **PARAMS)\n",
    "\n",
    "step, _ = env.reset()\n",
    "num_steps = 200\n",
    "for _ in range(num_steps):\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, terminated, truncated, info = env.step(action)\n",
    "    done = [any(i) for i in zip(terminated, truncated)] \n",
    "\n",
    "    state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7803a098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10%2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e1afc64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContinualEnv(gym.Env):\n",
    "\n",
    "    def __init__(self, params: list[dict], steps_per_env: int, num_envs: int = 1):\n",
    "        self.params = params\n",
    "        self.num_envs = num_envs\n",
    "        self.steps_per_env = steps_per_env\n",
    "        assert self.steps_per_env%self.num_envs == 0, \"steps_per_env must be divisible by num_envs\"\n",
    "\n",
    "        self.envs = [gym.make_vec(num_envs = self.num_envs, **param) for param in self.params]\n",
    "        self.current_env = 0\n",
    "        self.current_step = 0\n",
    "        self.current_env_instance = self.envs[self.current_env]\n",
    "        self.action_space = self.current_env_instance.action_space\n",
    "        self.observation_space = self.current_env_instance.observation_space\n",
    "\n",
    "        ## TODO: do i need action/observation spaces?\n",
    "    \n",
    "    def reset(self):\n",
    "        return self.current_env_instance.reset()\n",
    "    \n",
    "    def step(self, action):\n",
    "        next_state, reward, terminated, truncated, info = self.current_env_instance.step(action)\n",
    "        self.current_step += 1*self.num_envs\n",
    "        \n",
    "        if self.current_step >= self.steps_per_env:\n",
    "            print(f\"Switching to next environment: {self.current_env} -> {self.current_env + 1} at step {self.current_step}\")\n",
    "            self.current_env += 1\n",
    "            if self.current_env < len(self.envs):\n",
    "                self.current_env_instance = self.envs[self.current_env]\n",
    "                self.current_step = 0\n",
    "                next_state = self.current_env_instance.reset()\n",
    "            else:\n",
    "                print(\"No more environments to switch to. Continuing with the last environment.\")\n",
    "                ## TODO: handle end of environments gracefully\n",
    "        \n",
    "        return next_state, reward, terminated, truncated, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a37a5faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = [ \n",
    "        {\n",
    "            \"id\":\"LunarLander-v3\",\n",
    "            \"continuous\":False,\n",
    "            \"gravity\":-10.0,\n",
    "            \"enable_wind\": False,\n",
    "            \"wind_power\":15.0,\n",
    "            \"turbulence_power\":1.5\n",
    "        },\n",
    "        {\n",
    "            \"id\":\"LunarLander-v3\",\n",
    "            \"continuous\":False,\n",
    "            \"gravity\":-10.0,\n",
    "            \"enable_wind\": True,\n",
    "            \"wind_power\":15.0,\n",
    "            \"turbulence_power\":1.5\n",
    "        }\n",
    "    ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "030b4d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching to next environment: 0 -> 1 at step 1000\n",
      "Switching to next environment: 1 -> 2 at step 1000\n",
      "No more environments to switch to. Continuing with the last environment.\n"
     ]
    }
   ],
   "source": [
    "num_steps = 1000 * len(PARAMS) // 4\n",
    "c_env = ContinualEnv(PARAMS, steps_per_env=1000, num_envs=4)\n",
    "step, _ = c_env.reset()\n",
    "for _ in range(num_steps):\n",
    "    action = c_env.action_space.sample()\n",
    "    next_state, reward, terminated, truncated, info = c_env.step(action)\n",
    "    # print(f\"Step: {c_env.current_step}, Env: {c_env.current_env}, Action: {action}, Reward: {reward}\")\n",
    "    # print(f\"Terminated: {terminated}, Truncated: {truncated}, Info: {info}\")\n",
    "    done = [any(i) for i in zip(terminated, truncated)] \n",
    "    \n",
    "    # if done:\n",
    "    #     print(f\"Environment {c_env.current_env} finished after {c_env.current_step} steps.\")\n",
    "    #     step, _ = c_env.reset()\n",
    "    # else:\n",
    "    state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6186276",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContinualTrainer:\n",
    "\n",
    "    def __init__(self, env: ContinualEnv, agent, logger):\n",
    "        self.env = env\n",
    "        self.agent = agent\n",
    "        self.logger = logger\n",
    "\n",
    "    def train(self, num_epochs: int, steps_per_epoch: int = 1000):\n",
    "        \n",
    "        for _ in range(num_epochs):\n",
    "            state, _ = self.env.reset(self.seed)\n",
    "            for _ in range(steps_per_epoch):\n",
    "\n",
    "                action = self.agent.act(state)\n",
    "                next_state, reward, terminated, truncated, info = self.env.step(action)\n",
    "                done = [any(i) for i in zip(terminated, truncated)]\n",
    "\n",
    "                self.agent.record(state, action, reward, next_state, done)\n",
    "                self.logger.log(state, action, reward, next_state, done, info)\n",
    "                \n",
    "                state = next_state\n",
    "            \n",
    "            self.agent.update()\n",
    "            ## TODO: log agent performance, maybe save model\n",
    "            ## TODO: evaluate agent performance on all environments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
